## [Question 24 (Aug 8, 2024)](https://stackoverflow.com/questions/78850311/how-to-pass-system-prompt-to-claude-3-haiku-on-aws-bedrock-using-javascript-sdk)

How to pass system prompt to claude 3 haiku on AWS Bedrock Using JavaScript SDK V3

I can't figure out the correct way to pass a system prompt to claude 3 haiku through AWS Bedrock InvokeModelWithResponseStreamCommand. When I try to add { role: "system", content: systemPrompt } to the messages array it breaks. I've scoured Anthropic's and AWS Bedrock's documentation but can't find out whether system prompts are suppposed to be in a separate field from messages. According to anthropic docs it should be, but it does not appear that AWS Bedrock supports a separate system prompt field outside of messages in its JS SDK.

```
import { NextResponse } from "next/server";
import { BedrockRuntimeClient, InvokeModelWithResponseStreamCommand } from "@aws-sdk/client-bedrock-runtime";

const systemPrompt = "todo"

export async function POST(req) {

  // Create a Bedrock Runtime client in the AWS Region you want to use.
  const client = new BedrockRuntimeClient({ region: "us-east-1" });
  const data = await req.json();
  // Set the model ID, e.g., Claude 3 Haiku.
  const modelId = "anthropic.claude-3-haiku-20240307-v1:0";
  console.log(data)
  const payload = {
    anthropic_version: "bedrock-2023-05-31",
    max_tokens: 10000,
    messages: [
      {"role": "user", "content": "Hello there."},
      {"role": "assistant", "content": "Hi, I'm Claude. How can I help you?"},
      {"role": "user", "content": "Can you explain LLMs in plain English?"},
    ],
  }

  // Create a command with the model ID, the message, and a basic configuration.
  const command = new InvokeModelWithResponseStreamCommand({
    contentType: "application/json",
    body: JSON.stringify(payload),
    modelId,
  });
  
  const stream = new ReadableStream({
    async start(controller) {
      try {
        // Send the command to the model and wait for the response
        const response = await client.send(command);
        let completeMessage = "";
        // Extract and print the streamed response text in real-time.
        for await (const item of response.body) {
          const chunk = JSON.parse(new TextDecoder().decode(item.chunk.bytes));
          const chunk_type = chunk.type;
      
          if (chunk_type === "content_block_delta") {
            const text = chunk.delta.text;
            completeMessage = completeMessage + text;
            controller.enqueue(text);
            process.stdout.write(text);
          }
        }
      } catch (err) {
        controller.error(err)
      } finally {
        controller.close()
      }
    }
  })

  return new NextResponse(stream);
}
```
The error when I try to add the system prompt to the messages array:
```
Error: failed to pipe response
    ...
  [cause]: ValidationException: Malformed input request: #: subject must not be valid against schema {"required":["messages"]}#/messages/0/role: system is not a valid enum value, please reformat your input and try again.
      at de_ValidationExceptionRes (webpack-internal:///(rsc)/./node_modules/@aws-sdk/client-bedrock-runtime/dist-es/protocols/Aws_restJson1.js:379:23)
      at de_CommandError (webpack-internal:///(rsc)/./node_modules/@aws-sdk/client-bedrock-runtime/dist-es/protocols/Aws_restJson1.js:212:25)
      at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
      at async eval (webpack-internal:///(rsc)/./node_modules/@smithy/middleware-serde/dist-es/deserializerMiddleware.js:8:24)
      at async eval (webpack-internal:///(rsc)/./node_modules/@smithy/core/dist-es/middleware-http-signing/httpSigningMiddleware.js:25:20)
      at async eval (webpack-internal:///(rsc)/./node_modules/@smithy/middleware-retry/dist-es/retryMiddleware.js:41:46)
      at async eval (webpack-internal:///(rsc)/./node_modules/@aws-sdk/middleware-logger/dist-es/loggerMiddleware.js:9:26)
      at async Object.start (webpack-internal:///(rsc)/./app/api/chat/route.js:118:34) {
    '$fault': 'client',
    '$metadata': {
      httpStatusCode: 400,
      requestId: '5c49e0b0-d781-4c5a-bd7d-0823a50a763f',
      extendedRequestId: undefined,
      cfId: undefined,
      attempts: 1,
      totalRetryDelay: 0
    }
  }
}
 POST /api/chat 500 in 928ms
```
I've tried to add { role: "system", content: systemPrompt } as an additional message in the messages array and as a separate ("system") field. Using the external system field approach appears to be the correct way according to Anthropic's docs, but AWS Bedrock doesn't appear to support an external system field in its InvokeModelWithResponseStreamCommand Bedrock Runtime API. I'm expecting a streaming response that takes in user prompts and responds within the constraints of the system prompt.  
[https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html)  
[https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts)  
[https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/javascript_bedrock-runtime_code_examples.html#anthropic_claude](https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/javascript_bedrock-runtime_code_examples.html#anthropic_claude)  


## Baseline answer 

Looks like max_tokens can't be more than 4096 and the correct way is to pass in the prompt as a separate system field:
[https://github.com/aws/aws-sdk-js-v3/issues/5853](https://github.com/aws/aws-sdk-js-v3/issues/5853)  
[https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html#model-parameters-anthropic-claude-messages-request-response](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html#model-parameters-anthropic-claude-messages-request-response)  
The code below works in my experience:
```
const payload = {
    anthropic_version: "bedrock-2023-05-31",
    max_tokens: 4096,
    system: systemPrompt,
    messages: [
      {"role": "user", "content": "Hello there."},
      {"role": "assistant", "content": ""},
    ],
  }
```

## ChatGPT 4o

### **Fixing System Prompt Issue with Claude 3 Haiku on AWS Bedrock Using JavaScript SDK V3**

You're encountering the error:
```
Malformed input request: #: subject must not be valid against schema {"required":["messages"]}
```
This happens because **Claude 3 models in AWS Bedrock do not support `role: "system"` in the messages array** (unlike OpenAI's models).

---

## **Solution: Use `system` Field in Payload (Not Inside `messages`)**
AWS Bedrock supports system prompts for Claude 3 models using a **separate `system` field** in the request payload, instead of adding `{ role: "system", content: systemPrompt }` inside `messages`.

### **Corrected Code:**
Modify your `payload` to **include a separate `system` field**:
```js
const payload = {
  anthropic_version: "bedrock-2023-05-31",
  max_tokens: 10000,
  system: systemPrompt,  // âœ… System prompt goes here (outside messages)
  messages: [
    { "role": "user", "content": "Hello there." },
    { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },
    { "role": "user", "content": "Can you explain LLMs in plain English?" }
  ],
};
```

âœ… **Why?**
- AWS Bedrock requires system prompts to be **separate** from `messages`, unlike OpenAI models.
- This follows **Anthropicâ€™s latest prompt structure** for Claude models.

---

## **Solution 2: Confirm Claude 3 Haiku Model ID in AWS Bedrock**
Ensure your **Claude 3 model ID is correct**. The model ID for **Claude 3 Haiku** on AWS Bedrock should be:
```js
const modelId = "anthropic.claude-3-haiku-20240307-v1:0";
```
If you're using a different model, check available models in AWS Bedrock via:
```sh
aws bedrock list-foundation-models
```

---

## **Solution 3: Ensure Your AWS SDK Version Supports `system`**
If the `system` field does not work, ensure you're using the **latest AWS SDK V3**:
```sh
npm install @aws-sdk/client-bedrock-runtime@latest
```
Older versions might not support the `system` field properly.

---

## **Final Checklist**
| **Issue** | **Solution** |
|-----------|-------------|
| **AWS Bedrock rejects `role: "system"`** | Use **`system` field** outside `messages` |
| **Wrong model ID** | Use `"anthropic.claude-3-haiku-20240307-v1:0"` |
| **Older AWS SDK version** | Upgrade using `npm install @aws-sdk/client-bedrock-runtime@latest` |

After applying these fixes, your **Claude 3 Haiku system prompt should work correctly** in AWS Bedrock. ðŸš€ Let me know if you need further debugging!

## Gemini

The user has correctly identified the core issue: AWS Bedrock's implementation of the Claude 3 Haiku API, specifically through the JavaScript SDK v3's `InvokeModelWithResponseStreamCommand`, does not directly support a separate `system` prompt field as described in Anthropic's documentation. Instead, the system prompt must be incorporated into the `messages` array.

Here's a breakdown of the problem and the solution:

**Understanding the Problem:**

* **Anthropic's System Prompts:**
    * Anthropic's API documentation for Claude 3 emphasizes the use of a distinct `system` prompt field for setting the model's behavior.
* **AWS Bedrock's Implementation:**
    * AWS Bedrock's implementation, especially in the JavaScript SDK v3, requires system instructions to be included within the `messages` array.
    * The error, "system is not a valid enum value", confirms that the bedrock API does not accept system as a role.
* **SDK Discrepancy:**
    * This difference between Anthropic's native API and AWS Bedrock's adaptation causes confusion and errors.

**Solution:**

The correct approach is to include the system prompt as the *first* message in the `messages` array, using the `user` role. This effectively sets the context for the conversation.

**Modified JavaScript Code:**

```javascript
import { NextResponse } from "next/server";
import { BedrockRuntimeClient, InvokeModelWithResponseStreamCommand } from "@aws-sdk/client-bedrock-runtime";

const systemPrompt = "You are a helpful assistant that explains complex topics in a simple way.";

export async function POST(req) {
    const client = new BedrockRuntimeClient({ region: "us-east-1" });
    const data = await req.json();
    const modelId = "anthropic.claude-3-haiku-20240307-v1:0";
    console.log(data);

    const payload = {
        anthropic_version: "bedrock-2023-05-31",
        max_tokens: 10000,
        messages: [
            { "role": "user", "content": systemPrompt }, // System prompt as the first user message
            { "role": "user", "content": "Hello there." },
            { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },
            { "role": "user", "content": "Can you explain LLMs in plain English?" },
        ],
    };

    const command = new InvokeModelWithResponseStreamCommand({
        contentType: "application/json",
        body: JSON.stringify(payload),
        modelId,
    });

    const stream = new ReadableStream({
        async start(controller) {
            try {
                const response = await client.send(command);
                let completeMessage = "";
                for await (const item of response.body) {
                    const chunk = JSON.parse(new TextDecoder().decode(item.chunk.bytes));
                    const chunk_type = chunk.type;
                    if (chunk_type === "content_block_delta") {
                        const text = chunk.delta.text;
                        completeMessage = completeMessage + text;
                        controller.enqueue(text);
                        process.stdout.write(text);
                    }
                }
            } catch (err) {
                controller.error(err);
            } finally {
                controller.close();
            }
        },
    });

    return new NextResponse(stream);
}
```

**Key Changes:**

* **System Prompt Placement:**
    * The `systemPrompt` is now the first element in the `messages` array, with `role: "user"`.
* **Clarity:**
    * It is very important that the system prompt is the very first message.

**Important Notes:**

* **AWS Bedrock Documentation:**
    * It's essential to refer to the AWS Bedrock documentation for the most accurate and up-to-date information on model input and output formats.
* **Testing:**
    * Thoroughly test your implementation with different system prompts to ensure the model behaves as expected.
* **Model Behavior:**
    * Even with the system prompt correctly placed, the model's behavior can still vary. Experiment with different prompt formulations to achieve the desired results.
* **Keep up to date:**
    * AWS Bedrock and the underlying models are being updated frequently. Keep an eye on the AWS documentation for changes.


## Q

Maximum character count is 1000 characters.

## DeepSeek R1

To resolve the **"system prompt" issue with Claude 3 Haiku on AWS Bedrock**, use this modified approach:

### **Solution Code**
```javascript
const payload = {
  anthropic_version: "bedrock-2023-05-31",
  max_tokens: 10000,
  messages: [
    // System prompt embedded in first user message
    {
      role: "user",
      content: [
        {
          type: "text",
          text: `SYSTEM PROMPT: ${systemPrompt}\n\nUSER QUERY: Hello there.`
        }
      ]
    },
    // Rest of conversation history
    {"role": "assistant", "content": "Hi, I'm Claude. How can I help you?"},
    {"role": "user", "content": "Can you explain LLMs in plain English?"}
  ]
};
```

### **Key Fixes**
1. **Bedrock API Limitation**: AWS Bedrock's current Claude 3 implementation doesn't support the `system` field from Anthropic's native API
2. **Workaround**: Prepend system instructions to the first user message using:
   - Explicit formatting (e.g., "SYSTEM PROMPT: ...")
   - Natural language integration
3. **Message Structure**:
   ```typescript
   messages: Array<{
     role: "user" | "assistant";
     content: Array<{ type: "text"; text: string }>;
   }>
   ```

### **Alternative Approaches**
1. **Use Message History**:
   ```javascript
   messages: [
     {
       role: "user",
       content: [{
         type: "text", 
         text: `[System Instructions] ${systemPrompt}\n[User Message] Hello there.`
       }]
     }
   ]
   ```
   
2. **Leverage XML Tags**:
   ```javascript
   text: `<system>${systemPrompt}</system>\n<user>Hello there.</user>`
   ```

### **Verification Steps**
1. Check response quality matches system prompt guidance
2. Monitor token usage (system prompts count against input tokens)
3. Test with different formatting styles

### **Why This Works**
AWS Bedrock currently requires system prompts to be embedded in user messages due to API surface differences from Anthropic's native API. This pattern has been validated with Claude 3 models on Bedrock while maintaining streaming functionality.

Let me know if you need help with formatting variations or need to implement more complex prompt engineering patterns! ðŸš€

## ChatGPT o1



## Analysis 

Note: The five LLMs have been anonymized in the analysis below, as follows: ChatGPT-4o is Chatbot #1, Gemini 2.0 Flash is Chatbot #2, Q is Chatbot #3, DeepSeek R1 is Chatbot #4 and ChatGPT-o1 is Chatbot #5


